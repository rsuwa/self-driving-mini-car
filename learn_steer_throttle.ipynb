{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rsuwa/self-driving-mini-car/blob/main/learn_steer_throttle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "pnA6eW_SK4tH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "d4Hh1vlvLJWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/train_data_D | wc -l"
      ],
      "metadata": {
        "id": "QALwqNFaxrFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# フォルダのパスを設定\n",
        "folder_path = \"/content/drive/MyDrive/train_data_D\"  # 例: \"/path/to/your/folder\"\n",
        "\n",
        "# ステア角のリストを作成\n",
        "steer_angles = []\n",
        "\n",
        "# フォルダ内のすべてのファイルをループ\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".jpg\"):  # .jpgファイルのみを対象\n",
        "        # ステア角を取得\n",
        "        angle = filename.split(\"_\")[0]\n",
        "        try:\n",
        "            steer_angles.append(float(angle))\n",
        "        except ValueError:\n",
        "            print(f\"Could not convert {angle} to float from filename {filename}\")\n",
        "            continue\n",
        "\n",
        "# ステア角の分布をヒストグラムとしてプロット\n",
        "plt.hist(steer_angles, bins=50)\n",
        "plt.title(\"Distribution of Steer Angles\")\n",
        "plt.xlabel(\"Steer Angle\")\n",
        "plt.ylabel(\"Number of Images\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "iBNyZ1bCyZeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# フォルダのパスを設定\n",
        "folder_path = \"/content/drive/MyDrive/train_data_D\"  # 例: \"/path/to/your/folder\"\n",
        "\n",
        "# ステア角のリストを作成\n",
        "throttles = []\n",
        "\n",
        "# フォルダ内のすべてのファイルをループ\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".jpg\"):  # .jpgファイルのみを対象\n",
        "        # throttle値を取得\n",
        "        throttle = filename.split(\"_\")[1]\n",
        "        try:\n",
        "            throttles.append(float(throttle))\n",
        "        except ValueError:\n",
        "            print(f\"Could not convert {throttle} to float from filename {filename}\")\n",
        "            continue\n",
        "\n",
        "# ステア角の分布をヒストグラムとしてプロット\n",
        "plt.hist(throttles, bins=100)\n",
        "plt.title(\"Distribution of Throttle values\")\n",
        "plt.xlabel(\"Throttle value\")\n",
        "plt.ylabel(\"Number of Images\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "htv_ql5j0CJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import glob\n",
        "import PIL.Image\n",
        "import os\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "dJKNsK16Aogy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 無駄なファイル削除"
      ],
      "metadata": {
        "id": "yF0nYlangSkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def delete_files(start, end, dir_path, file_extension=\".jpg\"):\n",
        "    \"\"\"\n",
        "    Delete files in a numerical range with a specific extension.\n",
        "\n",
        "    :param start: Start of the numerical range\n",
        "    :param end: End of the numerical range\n",
        "    :param dir_path: Path to the directory containing the files\n",
        "    :param file_extension: Extension of the files to delete\n",
        "    \"\"\"\n",
        "    for i in range(start, end + 1):\n",
        "        # Generate filename\n",
        "        filename = f\"{i:04d}{file_extension}\"\n",
        "        file_path = os.path.join(dir_path, filename)\n",
        "\n",
        "        # Try to delete the file, and pass if it doesn't exist\n",
        "        try:\n",
        "            os.remove(file_path)\n",
        "            print(f\"Deleted: {file_path}\")\n",
        "        except FileNotFoundError:\n",
        "            print(f\"File not found: {file_path}\")\n",
        "            pass\n",
        "\n",
        "# Example usage:\n",
        "delete_files(0, 4000, \"/content/drive/MyDrive/train_data_D\")\n"
      ],
      "metadata": {
        "id": "G7Hfb51Tf7A8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## スロットル値が0に近い画像を削除"
      ],
      "metadata": {
        "id": "SSXkLBV2CMOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# フォルダのパスを設定\n",
        "folder_path = \"/content/drive/MyDrive/train_data_D\"  # 例: \"/path/to/your/folder\"\n",
        "throttle_threshold = 0.005 # スロットル値がこの値未満のファイルを削除\n",
        "steer_angle_threshold = 0.05\n",
        "cnt = 0\n",
        "# フォルダ内のすべてのファイルをループ\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".jpg\"):  # .jpgファイルのみを対象\n",
        "        # スロットル値を取得\n",
        "        throttle_str = filename.split(\"_\")[1]\n",
        "        # ステア値を取得\n",
        "        steer_angle_str = filename.split(\"_\")[0]\n",
        "        try:\n",
        "            throttle = float(throttle_str)\n",
        "            steer_angle = float(steer_angle_str)\n",
        "\n",
        "            # スロットル値が指定された閾値未満かをチェック\n",
        "            if abs(throttle) < throttle_threshold:\n",
        "                # and abs(steer_angle) < steer_angle_threshold:\n",
        "                file_path = os.path.join(folder_path, filename)\n",
        "                os.remove(file_path)\n",
        "                print(f\"Removed {filename}, steer={steer_angle}, throttle={throttle}\")\n",
        "                cnt += 1\n",
        "        except ValueError:\n",
        "            print(f\"Could not convert {throttle_str} to float from filename {filename}\")\n",
        "            continue\n",
        "print(cnt)\n"
      ],
      "metadata": {
        "id": "6pv0G9UqBbMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_steering(path):\n",
        "    \"\"\"Gets the steering value from the image filename\"\"\"\n",
        "    gets = path.split('_')\n",
        "    return float(gets[0])\n",
        "\n",
        "def get_speed(path):\n",
        "    \"\"\"Gets the speed value from the image filename\"\"\"\n",
        "    gets = path.split('_')\n",
        "    return float(gets[1])\n",
        "\n",
        "class SSDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, directory, random_hflips=False):\n",
        "        self.directory = directory\n",
        "        self.random_hflips = random_hflips\n",
        "        self.image_paths = glob.glob(os.path.join(self.directory, '*.jpg'))\n",
        "        self.color_jitter = transforms.ColorJitter(0.3, 0.3, 0.3, 0.3)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "\n",
        "        image = PIL.Image.open(image_path)\n",
        "        x = float(get_steering(os.path.basename(image_path)))\n",
        "        y = float(get_speed(os.path.basename(image_path)))\n",
        "\n",
        "        image = self.color_jitter(image)\n",
        "        image = transforms.functional.resize(image, (224, 224))\n",
        "        image = transforms.functional.to_tensor(image)\n",
        "        image = image.numpy()[::-1].copy()\n",
        "        image = torch.from_numpy(image)\n",
        "        image = transforms.functional.normalize(image, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "\n",
        "        return image, torch.tensor([x, y]).float()\n",
        "\n",
        "dataset = SSDataset('/content/drive/MyDrive/train_data_D', random_hflips=False)"
      ],
      "metadata": {
        "id": "jKlphr1oCtJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_percent = 0.1\n",
        "num_test = int(test_percent * len(dataset))\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - num_test, num_test])\n"
      ],
      "metadata": {
        "id": "Wh31xHIfC52I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=16,\n",
        "    shuffle=True,\n",
        "    num_workers=4\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=16,\n",
        "    shuffle=True,\n",
        "    num_workers=4\n",
        ")"
      ],
      "metadata": {
        "id": "4wRRLWjgC_mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(pretrained=True)"
      ],
      "metadata": {
        "id": "hjjD9E8-DD5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fc = torch.nn.Linear(512, 2)\n",
        "device = torch.device('cuda')\n",
        "model = model.to(device)\n",
        "\n",
        "# Frozen for modle layer1 to layer3\n",
        "for l in model.layer1.parameters():\n",
        "    l.requires_grad=False\n",
        "for l in model.layer2.parameters():\n",
        "    l.requires_grad=False\n",
        "for l in model.layer3.parameters():\n",
        "    l.requires_grad=False"
      ],
      "metadata": {
        "id": "65VT4miIDF9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EARLY_STOP = True\n",
        "\n",
        "\n",
        "NUM_EPOCHS = 100\n",
        "BEST_MODEL_PATH = 'best_steering_model_ResNet.pth'\n",
        "best_loss = 1e9\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "es_counter = 0\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for images, labels in iter(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = F.mse_loss(outputs, labels)\n",
        "        loss.backward()\n",
        "        train_loss += float(loss)\n",
        "        optimizer.step()\n",
        "    train_loss /= len(train_loader)\n",
        "\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    for images, labels in iter(test_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = F.mse_loss(outputs, labels)\n",
        "        test_loss += float(loss)\n",
        "    test_loss /= len(test_loader)\n",
        "    print('%d, %f, %f' % (epoch, train_loss, test_loss))\n",
        "    if test_loss < best_loss:\n",
        "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
        "        best_loss = test_loss\n",
        "        es_counter=0\n",
        "    else:\n",
        "        if es_counter == 10 and EARLY_STOP:\n",
        "            print(\"Early Stopping EPOCH[{}], val_loss {:4f}\".format(epoch, best_loss))\n",
        "            break\n",
        "        else:\n",
        "            es_counter += 1\n"
      ],
      "metadata": {
        "id": "I2JNwJ5iDiZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_DATA_IMAGE = '/content/drive/MyDrive/train_data_D/1.000000_-0.128851_00dd6bba-6100-11ee-b386-0242c6b6e9d9.jpg'\n",
        "\n",
        "model = torchvision.models.resnet18(pretrained=False)\n",
        "model.fc = torch.nn.Linear(512, 2)\n",
        "model.load_state_dict(torch.load('best_steering_model_ResNet.pth'))\n",
        "model = model.to(device)\n",
        "model = model.eval()\n",
        "image_path = TEST_DATA_IMAGE\n",
        "image = PIL.Image.open(image_path)\n",
        "image = transforms.functional.resize(image, (224, 224))\n",
        "image = transforms.functional.to_tensor(image)\n",
        "image = image.numpy()[::-1].copy()\n",
        "image = torch.from_numpy(image)\n",
        "image = transforms.functional.normalize(image, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]).to(device)\n",
        "outputs = model(image[None, ...])\n",
        "print(outputs)"
      ],
      "metadata": {
        "id": "VcPJ23NsDoci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = PIL.Image.open(image_path)\n",
        "image_orig_size = image.size\n",
        "\n",
        "sample_image = transforms.functional.resize(image, (224, 224))\n",
        "\n",
        "\n",
        "sample_image = transforms.functional.to_tensor(sample_image)\n",
        "sample_image = sample_image.numpy()[::-1].copy()\n",
        "sample_image = torch.from_numpy(sample_image)\n",
        "sample_image = transforms.functional.normalize(sample_image, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]).to(device)"
      ],
      "metadata": {
        "id": "KY_OJoM9EKBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://tech.jxpress.net/entry/2018/12/12/130057\n",
        "# https://jacobgil.github.io/deeplearning/vehicle-steering-angle-visualizations\n",
        "class GradCAM:\n",
        "    def __init__(self, model, feature_layer):\n",
        "        self.model = model\n",
        "        self.feature_layer = feature_layer\n",
        "        self.model.eval()\n",
        "        self.feature_grad = None\n",
        "        self.feature_map = None\n",
        "        self.hooks = []\n",
        "\n",
        "        # 最終層逆伝播時の勾配を記録する\n",
        "        def save_feature_grad(module, in_grad, out_grad):\n",
        "            self.feature_grad = out_grad[0]\n",
        "        self.hooks.append(self.feature_layer.register_backward_hook(save_feature_grad))\n",
        "\n",
        "        # 最終層の出力 Feature Map を記録する\n",
        "        def save_feature_map(module, inp, outp):\n",
        "            self.feature_map = outp[0]\n",
        "        self.hooks.append(self.feature_layer.register_forward_hook(save_feature_map))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def backward_on_target(self,output):\n",
        "        self.model.zero_grad()\n",
        "        output.backward()\n",
        "\n",
        "    def clear_hook(self):\n",
        "        for hook in self.hooks:\n",
        "            hook.remove()\n"
      ],
      "metadata": {
        "id": "4nrowKm2ENVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "grad_cam = GradCAM(model=model, feature_layer=list(model.layer4.modules())[-1])"
      ],
      "metadata": {
        "id": "ZEdkyCfUEQHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_output = grad_cam.forward(sample_image[None, ...])\n",
        "print(model_output)\n",
        "#model_output.backward()\n",
        "grad_cam.backward_on_target(model_output[0][0])"
      ],
      "metadata": {
        "id": "wh7KAOvvERlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Get feature gradient\n",
        "feature_grad = grad_cam.feature_grad.data.cpu().numpy()[0]\n",
        "# Get weights from gradient\n",
        "weights = np.mean(feature_grad, axis=(1, 2))  # Take averages for each gradient\n",
        "# Get features outputs\n",
        "feature_map = grad_cam.feature_map.data.cpu().numpy()\n",
        "grad_cam.clear_hook()"
      ],
      "metadata": {
        "id": "2aq9Mo7BEUPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get cam\n",
        "cam = np.sum((weights * feature_map.T), axis=2).T\n",
        "cam = np.maximum(cam, 0)  # apply ReLU to cam"
      ],
      "metadata": {
        "id": "_UFVmUIrEVsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cam)"
      ],
      "metadata": {
        "id": "LMCfLhAxEXQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#(cam*10000).astype(np.uint8)\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "cam = cv2.resize(cam, (224,224))\n",
        "cam = (cam - np.min(cam)) / (np.max(cam) - np.min(cam))  # Normalize between 0-1\n",
        "cam = np.uint8(cam * 255)  # Scale between 0-255 to visualize\n",
        "plt.imshow(cam)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-6ddYQqAEVq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "activation_heatmap = np.expand_dims(cam, axis=0).transpose(1,2,0)\n",
        "org_img = np.asarray(image.resize((224,224)))\n",
        "img_with_heatmap = np.multiply(np.float32(activation_heatmap), np.float32(org_img))\n",
        "img_with_heatmap = img_with_heatmap / np.max(img_with_heatmap)\n",
        "org_img = cv2.resize(org_img, image_orig_size)"
      ],
      "metadata": {
        "id": "zLVUGoJ_EaT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(org_img)\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(cv2.resize(np.uint8(255 * img_with_heatmap), image_orig_size))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ij06IQ4PEbiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vh8tVo16gPLM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}